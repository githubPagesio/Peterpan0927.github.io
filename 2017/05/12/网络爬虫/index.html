<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>网络爬虫 | Peterpan&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="网络爬虫">
<meta property="og:url" content="http://yoursite.com/2017/05/12/网络爬虫/index.html">
<meta property="og:site_name" content="Peterpan's Blog">
<meta property="og:description" content="学习笔记">
<meta property="og:image" content="http://omg5mjb8v.bkt.clouddn.com/AE9908A0-44A5-4B78-8557-360650F1CFFF.png">
<meta property="og:image" content="http://omg5mjb8v.bkt.clouddn.com/37300744-19C5-4DD5-8D90-606A58200F0A.png">
<meta property="og:image" content="http://omg5mjb8v.bkt.clouddn.com/20130515113723855-e1424095177180.png">
<meta property="og:updated_time" content="2017-05-12T12:03:06.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="网络爬虫">
<meta name="twitter:description" content="学习笔记">
<meta name="twitter:image" content="http://omg5mjb8v.bkt.clouddn.com/AE9908A0-44A5-4B78-8557-360650F1CFFF.png">
  
    <link rel="alternative" href="/atom.xml" title="Peterpan&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  
      <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            
            <img lazy-src="/img/head.jpg" class="js-avatar">
            
        </a>

        <hgroup>
          <h1 class="header-author"><a href="/" title="Hi Mate">Peter pan</a></h1>
        </hgroup>

        
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="http://118.89.38.168">博客首页</a></li>
                        
                            <li><a href="/works">作品展示</a></li>
                        
                            <li><a href="/about">留言打卡</a></li>
                        
                            <li><a href="/FrontEndGuide">前端导航</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail" target="_blank" href="https://mail.qq.com/cgi-bin/frame_html?sid=_oJT_9NAAluUNmoy&r=19ceffb7525880fec0778e401ab5a0c5" title="mail">mail</a>
                            
                                <a class="fl github" target="_blank" href="https://github.com/Peterpan0927" title="github">github</a>
                            
                                <a class="fl zhihu" target="_blank" href="https://www.zhihu.com" title="zhihu">zhihu</a>
                            
                                <a class="fl weibo" target="_blank" href="https://passport.weibo.com/visitor/visitor?entry=miniblog&a=enter&url=http%3A%2F%2Fweibo.com%2F&domain=.weibo.com&sudaref=https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DXJx2tZ7NciddPrWFwVpBgDI3XPGsiz4nrRDKFMkcfWu%26wd%3D%26eqid%3Dc1afc8ed00048e800000000358cf9830&ua=php-sso_sdk_client-0.6.23&_rand=1489999922.7477" title="weibo">weibo</a>
                            
                                <a class="fl google" target="_blank" href="#" title="google">google</a>
                            
                                <a class="fl twitter" target="_blank" href="#" title="twitter">twitter</a>
                            
                                <a class="fl linkedin" target="_blank" href="#" title="linkedin">linkedin</a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/ARC-分类-MRC和ARC转换和兼容/" style="font-size: 10px;">ARC 分类 MRC和ARC转换和兼容</a> <a href="/tags/Linux内核/" style="font-size: 10px;">Linux内核</a> <a href="/tags/TableView-cell/" style="font-size: 10px;">TableView cell</a> <a href="/tags/Web安全-前后端基础/" style="font-size: 10px;">Web安全  前后端基础</a> <a href="/tags/Xcode/" style="font-size: 10px;">Xcode</a> <a href="/tags/hexo-github/" style="font-size: 10px;">hexo github</a> <a href="/tags/iOS-OC/" style="font-size: 10px;">iOS OC</a> <a href="/tags/iOS-UI/" style="font-size: 10px;">iOS UI</a> <a href="/tags/中文编码解决/" style="font-size: 10px;">中文编码解决</a> <a href="/tags/交互式笔记本/" style="font-size: 10px;">交互式笔记本</a> <a href="/tags/代理设计的理解/" style="font-size: 10px;">代理设计的理解</a> <a href="/tags/内存管理-MRC/" style="font-size: 10px;">内存管理 MRC</a> <a href="/tags/图片拉伸-通知-虚拟键盘/" style="font-size: 10px;">图片拉伸 通知 虚拟键盘</a> <a href="/tags/基础介绍-正则匹配/" style="font-size: 10px;">基础介绍 正则匹配</a> <a href="/tags/成员变量和属性变量-真私有属性/" style="font-size: 10px;">成员变量和属性变量 真私有属性</a> <a href="/tags/数据库和HighCharts调用/" style="font-size: 10px;">数据库和HighCharts调用</a> <a href="/tags/无框架原生爬虫/" style="font-size: 10px;">无框架原生爬虫</a> <a href="/tags/樱花下落的速度是每秒五厘米么？/" style="font-size: 10px;">樱花下落的速度是每秒五厘米么？</a> <a href="/tags/汇编基础/" style="font-size: 10px;">汇编基础</a> <a href="/tags/简单微博-MVC实现/" style="font-size: 10px;">简单微博 MVC实现</a> <a href="/tags/类的本质-重写init-点语法/" style="font-size: 10px;">类的本质 重写init 点语法</a> <a href="/tags/较完善的App/" style="font-size: 10px;">较完善的App</a> <a href="/tags/非对称加密算法/" style="font-size: 10px;">非对称加密算法</a>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="http://luuman.github.io/">name</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">二次元、爱运动、爱交友、爱旅行、喜欢接触新鲜事物、迎接新的挑战，更爱游离于错综复杂的编码与逻辑中</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">Peter pan</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">Peter pan</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="http://118.89.38.168">博客首页</a></li>
                
                    <li><a href="/works">作品展示</a></li>
                
                    <li><a href="/about">留言打卡</a></li>
                
                    <li><a href="/FrontEndGuide">前端导航</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="https://mail.qq.com/cgi-bin/frame_html?sid=_oJT_9NAAluUNmoy&r=19ceffb7525880fec0778e401ab5a0c5" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/Peterpan0927" title="github">github</a>
                    
                        <a class="zhihu" target="_blank" href="https://www.zhihu.com" title="zhihu">zhihu</a>
                    
                        <a class="weibo" target="_blank" href="https://passport.weibo.com/visitor/visitor?entry=miniblog&a=enter&url=http%3A%2F%2Fweibo.com%2F&domain=.weibo.com&sudaref=https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DXJx2tZ7NciddPrWFwVpBgDI3XPGsiz4nrRDKFMkcfWu%26wd%3D%26eqid%3Dc1afc8ed00048e800000000358cf9830&ua=php-sso_sdk_client-0.6.23&_rand=1489999922.7477" title="weibo">weibo</a>
                    
                        <a class="google" target="_blank" href="#" title="google">google</a>
                    
                        <a class="twitter" target="_blank" href="#" title="twitter">twitter</a>
                    
                        <a class="linkedin" target="_blank" href="#" title="linkedin">linkedin</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap"><article id="post-网络爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/05/12/网络爬虫/" class="article-date">
      <time datetime="2017-05-12T11:48:24.000Z" itemprop="datePublished">2017-05-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      网络爬虫
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/基础介绍-正则匹配/">基础介绍 正则匹配</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>学习笔记<br><a id="more"></a></p>
<h1 id="网络爬虫"><a href="#网络爬虫" class="headerlink" title="网络爬虫"></a>网络爬虫</h1><p>什么是爬虫？</p>
<p>网络爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动的抓取万维网信息的程序或者脚本。<br>简单的来说，爬虫就是把别人网站的信息弄到自己的电脑上，再做一些过滤，筛选，归纳，整理，排序等等，如果数据量足够大，算法足够好，能给别人提供优质的检索服务，就可以做成类似google或baidu</p>
<p>为什么选择python写爬虫？</p>
<p>1）抓取网页本身的接口<br>相比与其他静态编程语言，如java，c#，C++，python抓取网页文档的接口更简洁；相比其他动态脚本语言，如perl，shell，python的urllib2包提供了较为完整的访问网页文档的API。（当然ruby也是很好的选择）<br>此外，抓取网页有时候需要模拟浏览器的行为，很多网站对于生硬的爬虫抓取都是封杀的。这是我们需要模拟user agent的行为构造合适的请求，譬如模拟用户登陆、模拟session/cookie的存储和设置。在python里都有非常优秀的第三方包帮你搞定，如Requests，mechanize等等。</p>
<p>2）网页抓取后的处理<br>抓取的网页通常需要处理，比如过滤html标签，提取文本等。python的beautifulsoap提供了简洁的文档处理功能，能用极短的代码完成大部分文档的处理。</p>
<p>其实以上功能很多语言和工具都能做，但是用python能够干得最快，最干净。</p>
<h2 id="1-urlopen"><a href="#1-urlopen" class="headerlink" title="1.urlopen:"></a>1.urlopen:</h2><p>打开一个url方法，返回一个文件对象，然后就可以进行类似文件对象的操作。模块：urllib</p>
<p><img src="http://omg5mjb8v.bkt.clouddn.com/AE9908A0-44A5-4B78-8557-360650F1CFFF.png" alt=""></p>
<h2 id="2-urlretrieve"><a href="#2-urlretrieve" class="headerlink" title="2.urlretrieve():"></a>2.urlretrieve():</h2><p>urlretrieve方法将url定位到的html文件下载到你的本地硬盘当中,模块：utllib,当没有指定路径的时候可以放到临时路径下面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib</div><div class="line">a = urllib.urlretrieve(<span class="string">"xxx"</span>,filename = <span class="string">"/home/xx/xx/xx.xx"</span>)</div><div class="line"><span class="comment">#将a保存在本地硬盘中，可用的方法和urlopen相同,可以选择保存的路径</span></div></pre></td></tr></table></figure>
<h2 id="3-使用正则获取图片并保存在本地"><a href="#3-使用正则获取图片并保存在本地" class="headerlink" title="3.使用正则获取图片并保存在本地"></a>3.使用正则获取图片并保存在本地</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line">imgList = re.findall(<span class="string">r'src="(.*?\.(jpg|png))"'</span>,html)</div><div class="line">x = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> imgurl <span class="keyword">in</span> imgList:</div><div class="line">    print(<span class="string">'正在下载%s'</span>%imgurl[<span class="number">0</span>])</div><div class="line">    urllib.urlretrieve(imgurl[<span class="number">0</span>],<span class="string">'./downloads/%d.jpg'</span>%x)</div><div class="line">    x += <span class="number">1</span></div></pre></td></tr></table></figure>
<h2 id="4-urlencode-GET和POST方法"><a href="#4-urlencode-GET和POST方法" class="headerlink" title="4.urlencode,GET和POST方法"></a>4.urlencode,GET和POST方法</h2><p>最重要的区别是GET方式是直接以链接形式访问，链接中包含了所有的参数，当然如果包含了密码的话是一种不安全的选择，不过你可以直观地看到自己提交了什么内容。POST则不会在网址上显示所有的参数，不过如果你想直接查看提交了什么就不太方便了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"> </div><div class="line">values = &#123;&#125;</div><div class="line">values[<span class="string">'username'</span>] = <span class="string">"1016903103@qq.com"</span></div><div class="line">values[<span class="string">'password'</span>] = <span class="string">"XXXX"</span></div><div class="line">data = urllib.urlencode(values) </div><div class="line">url = <span class="string">"http://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn"</span></div><div class="line">request = urllib2.Request(url,data)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line"><span class="keyword">print</span> response.read()</div><div class="line"><span class="comment">#POST方法，构建request时传入两个参数，url和data</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> urllib</div><div class="line">values=&#123;&#125;</div><div class="line">values[<span class="string">'username'</span>] = <span class="string">"1016903103@qq.com"</span></div><div class="line">values[<span class="string">'password'</span>]=<span class="string">"XXXX"</span></div><div class="line">data = urllib.urlencode(values) </div><div class="line">url = <span class="string">"http://passport.csdn.net/account/login"</span></div><div class="line">geturl = url + <span class="string">"?"</span>+data</div><div class="line">request = urllib2.Request(geturl)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line"><span class="keyword">print</span> response.read()</div><div class="line"><span class="comment">#GET方法，直接把参数写到网址上面，直接构建一个带参数的URL出来即可。</span></div></pre></td></tr></table></figure>
<h2 id="5-urllib2和伪造请求头部"><a href="#5-urllib2和伪造请求头部" class="headerlink" title="5.urllib2和伪造请求头部"></a>5.urllib2和伪造请求头部</h2><p>目的：是服务器分不清你是爬虫还是浏览器</p>
<p><img src="http://omg5mjb8v.bkt.clouddn.com/37300744-19C5-4DD5-8D90-606A58200F0A.png" alt=""></p>
<p>设置Headers:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">url = <span class="string">'http://www.server.com/login'</span></div><div class="line">user_agent = <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4)'</span></div><div class="line">values = &#123;<span class="string">'username'</span> : <span class="string">'pzp'</span>, <span class="string">'password'</span> : <span class="string">'ascndksv'</span>&#125;</div><div class="line">headers = &#123;<span class="string">'User-Agent'</span> : user_agent&#125;</div><div class="line">data = urllib.urlencode(value)</div><div class="line">request = urllib.Request(url, data, headers)</div><div class="line">response = urllib.urlopen(request)</div><div class="line">page = response.read()</div><div class="line"><span class="comment">#服务器会识别headers中的referer是不是它自己，如果不是，有的服务器不会响应，所以我们还可以在headers中加入referer,这样就可以应付防盗链了</span></div><div class="line">headers = &#123;<span class="string">'User-Agent'</span> : user_agent, <span class="string">'Referer'</span> : <span class="string">'xxxxxx'</span>&#125;</div></pre></td></tr></table></figure>
<p>关于headers的其他属性：</p>
<blockquote>
<p>User-Agent : 有些服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求</p>
<p>Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。</p>
<p>application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用</p>
<p>application/json ： 在 JSON RPC 调用时使用</p>
<p>application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用</p>
<p>在使用服务器提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致服务器拒绝服务</p>
</blockquote>
<h2 id="6-BeautifulSoup参考文章"><a href="#6-BeautifulSoup参考文章" class="headerlink" title="6.BeautifulSoup参考文章"></a>6.BeautifulSoup<a href="http://www.cnblogs.com/yupeng/p/3362031.html" target="_blank" rel="external">参考文章</a></h2><p>Beautiful Soup 是用Python写的一个HTML/XML的解析器，它可以很好的处理不规范标记并生成剖析树(parse tree)。 它提供简单又常用的导航（navigating），搜索以及修改剖析树的操作。它可以大大节省你的编程时间。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">html = urllib2.urlopen(<span class="string">"xxxxx"</span>)</div><div class="line">html = html.read()</div><div class="line">soup = BeautifulSoup(html)</div><div class="line"><span class="comment">#下面是几个常用的功能</span></div><div class="line">soup.标签名  <span class="comment">#只会显示第一个</span></div><div class="line">soup.select(<span class="string">'标签名'</span>)</div><div class="line">soup.select(<span class="string">'.类名'</span>)</div><div class="line">soup.select(<span class="string">'#id名'</span>)</div><div class="line"><span class="comment">#可以通过标签名，类名，id名来寻找，可以找出所有的</span></div><div class="line">soup.select(<span class="string">'标签名 id'</span>)  <span class="comment">#组合查找</span></div><div class="line">soup.select(<span class="string">'head &gt; title'</span>) <span class="comment">#子标签查找</span></div><div class="line">soup.select(<span class="string">'a[class="sister"]'</span>)  <span class="comment">#属性查找</span></div><div class="line">soup.标签名.string   <span class="comment">#获取文字</span></div><div class="line">soup.标签名.attrs    <span class="comment">#获取属性</span></div><div class="line"><span class="comment">#通过遍历树来寻找</span></div><div class="line">soup.find_all(<span class="string">'name, attrs, recursive, text, limit, **kwargs'</span>)</div><div class="line"><span class="comment">#get_text</span></div><div class="line">soup.get_text()<span class="comment">#获取文字信息，类似于string，但是string只能对一个对象使用</span></div><div class="line">soup.stripped_string<span class="comment">#类似于get_text（）方法，但是会获取所有子标签的文字信息</span></div></pre></td></tr></table></figure></p>
<h2 id="7-使用select不断筛选-取得属性"><a href="#7-使用select不断筛选-取得属性" class="headerlink" title="7.使用select不断筛选,取得属性"></a>7.使用select不断筛选,取得属性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#之前的过程省略,此时yy是一个列表，不能对他进行筛选操作</span></div><div class="line">yy = soup select(<span class="string">'div[id=xxx]'</span>)</div><div class="line"><span class="comment">#此时将列表又转换成了对象，可以继续操作了</span></div><div class="line">zz = yy[<span class="number">0</span>]</div><div class="line"><span class="comment">#指向性的提取对象中的属性</span></div><div class="line">zz[<span class="string">'href'</span>]</div><div class="line"><span class="comment">#将对象转换成列表</span></div><div class="line">list(xxx)</div></pre></td></tr></table></figure>
<h2 id="8-urlopen的分析"><a href="#8-urlopen的分析" class="headerlink" title="8.urlopen的分析"></a>8.urlopen的分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">urlopen(url, data, timeout)</div><div class="line"><span class="comment">#第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。</span></div><div class="line"></div><div class="line"><span class="comment">#第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT</span></div><div class="line"></div><div class="line"><span class="comment">#第一个参数URL是必须要传送的</span></div></pre></td></tr></table></figure>
<h2 id="9-构造Request"><a href="#9-构造Request" class="headerlink" title="9.构造Request"></a>9.构造Request</h2><p>其实上面的urlopen参数可以传入一个request请求,它其实就是一个Request类的实例，构造时需要传入Url,Data等等的内容。因为在构建请求时还需要加入好多内容，通过构建一个request，服务器响应请求得到应答，这样显得逻辑上清晰明确。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"> </div><div class="line">request = urllib2.Request(<span class="string">"http://www.baidu.com"</span>)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line"><span class="keyword">print</span> response.read()</div></pre></td></tr></table></figure>
<h2 id="10-Proxy（代理）的设置"><a href="#10-Proxy（代理）的设置" class="headerlink" title="10.Proxy（代理）的设置"></a>10.Proxy（代理）的设置</h2><p>urllib2 默认会使用环境变量 http_proxy 来设置 HTTP Proxy。假如一个网站它会检测某一段时间某个IP 的访问次数，如果访问次数过多，它会禁止你的访问。所以你可以设置一些代理服务器来帮助你做工作，每隔一段时间换一个代理，就不知道到底是谁了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">enable_proxy = <span class="keyword">True</span></div><div class="line">proxy_handler = urllib2.ProxyHandler(&#123;<span class="string">"http"</span> : <span class="string">'http://some-proxy.com:8080'</span>&#125;)</div><div class="line">null_proxy_handler = urllib2.ProxyHandler(&#123;&#125;)</div><div class="line"><span class="keyword">if</span> enable_proxy:</div><div class="line">    opener = urllib2.build_opener(proxy_handler)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    opener = urllib2.build_opener(null_proxy_handler)</div><div class="line">urllib2.install_opener(opener)</div></pre></td></tr></table></figure>
<h2 id="11-Timeout设置"><a href="#11-Timeout设置" class="headerlink" title="11.Timeout设置"></a>11.Timeout设置</h2><p>可以设置等待多久超时，为了解决一些网站实在响应过慢而造成的影响。如果第二个参数data为空那么要特别指定是timeout是多少，写明形参，如果data已经传入，则不必声明。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">response = urllib2.urlopen(<span class="string">'http://www.baidu.com'</span>, data, <span class="number">10</span>)</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">response = urllib2.urlopen(<span class="string">'http://www.baidu.com'</span>, timeout=<span class="number">10</span>)</div></pre></td></tr></table></figure>
<h2 id="12-PUT和DELETE方法"><a href="#12-PUT和DELETE方法" class="headerlink" title="12.PUT和DELETE方法"></a>12.PUT和DELETE方法</h2><p>PUT：这个方法比较少见。HTML表单也不支持这个。本质上来讲， PUT和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定DELETE：删除某一个资源。基本上这个也很少见，不过还是有一些地方比如amazon的S3云服务里面就用的这个方法来删除资源。</p>
<h2 id="13-URLError"><a href="#13-URLError" class="headerlink" title="13.URLError"></a>13.URLError</h2><p>产生原因：</p>
<ul>
<li>网络无连接，即本机无法上网</li>
<li>连接不到特定的服务器</li>
<li>服务器不存在</li>
</ul>
<p>在代码中可以通过捕获异常来判断原因：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line">requset = urllib2.Request(<span class="string">'http://www.xxxxx.com'</span>)</div><div class="line"><span class="keyword">try</span>:</div><div class="line">    urllib2.urlopen(request)</div><div class="line"><span class="keyword">except</span> urllib2.URLError, e:</div><div class="line">    <span class="keyword">print</span> e.reason</div><div class="line"><span class="comment">#如果访问了一个不存在的网址，那么运行的结果是：[Errno 11004] getaddrinfo failed</span></div></pre></td></tr></table></figure>
<p>HTTPError,是URLError的子类，所以也可以将父类捕获异常写在子类的后面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line">req = urllib2.Request(<span class="string">'http://blog.csdn.net/cqcre'</span>)</div><div class="line"><span class="keyword">try</span>:</div><div class="line">    urllib2.urlopen(req)</div><div class="line"><span class="keyword">except</span> urllib2.HTTPError, e:</div><div class="line">    <span class="keyword">print</span> e.code</div><div class="line"><span class="keyword">except</span> urllib2.URLError, e:</div><div class="line">    <span class="keyword">print</span> e.reason</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    <span class="keyword">print</span> (<span class="string">"OK"</span>)</div><div class="line"><span class="comment">#样例检错：403</span></div></pre></td></tr></table></figure>
<h2 id="14-Opener概念"><a href="#14-Opener概念" class="headerlink" title="14.Opener概念"></a>14.Opener概念</h2><blockquote>
<p>Cookie，指某些网站为了辨别用户身份、进行session跟踪而储存在用户本地终端上的数据（通常经过加密）比如说有些网站需要登录后才能访问某个页面，在登录之前，你想抓取某个页面内容是不允许的。那么我们可以利用Urllib2库保存我们登录的Cookie，然后再抓取其他页面就达到目的了。</p>
<p>当你获取一个URL你使用一个opener(一个urllib2.OpenerDirector的实例)。在前面，我们都是使用的默认的opener，也就是urlopen。它是一个特殊的opener，可以理解成opener的一个特殊实例，传入的参数仅仅是url，data，timeout。</p>
<p>如果我们需要用到Cookie，只用这个opener是不能达到目的的，所以我们需要创建更一般的opener来实现对Cookie的设置。</p>
</blockquote>
<h2 id="15-Cookielib"><a href="#15-Cookielib" class="headerlink" title="15.Cookielib"></a>15.Cookielib</h2><p>该模块主要的对象有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar。</p>
<p>1.获取Cookie保存到变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> cookielib</div><div class="line"><span class="comment">#声明一个CookieJar对象实例来保存cookie</span></div><div class="line">cookie = cookielib.CookieJar()</div><div class="line"><span class="comment">#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器</span></div><div class="line">handler=urllib2.HTTPCookieProcessor(cookie)</div><div class="line"><span class="comment">#通过handler来构建opener</span></div><div class="line">opener = urllib2.build_opener(handler)</div><div class="line"><span class="comment">#此处的open方法同urllib2的urlopen方法，也可以传入request</span></div><div class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</div><div class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie:</div><div class="line">    <span class="keyword">print</span> <span class="string">'Name = '</span>+item.name</div><div class="line">    <span class="keyword">print</span> <span class="string">'Value = '</span>+item.value</div></pre></td></tr></table></figure>
<p>2.保存Cookie到文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> cookielib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line"><span class="comment">#设置保存cookie的文件，同级目录下的cookie.txt</span></div><div class="line">filename = <span class="string">'cookie.txt'</span></div><div class="line"><span class="comment">#声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件</span></div><div class="line">cookie = cookielib.MozillaCookieJar(filename)</div><div class="line"><span class="comment">#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器</span></div><div class="line">handler = urllib2.HTTPCookieProcessor(cookie)</div><div class="line"><span class="comment">#通过handler来构建opener</span></div><div class="line">opener = urllib2.build_opener(handler)</div><div class="line"><span class="comment">#创建一个请求，原理同urllib2的urlopen</span></div><div class="line">response = opener.open(<span class="string">"http://www.baidu.com"</span>)</div><div class="line"><span class="comment">#保存cookie到文件</span></div><div class="line">cookie.save(ignore_discard=<span class="keyword">True</span>, ignore_expires=<span class="keyword">True</span>)</div><div class="line"><span class="comment">#ignore_discard的意思是即使cookies将被丢弃也将它保存下来</span></div><div class="line"><span class="comment">#ignore_expires的意思是如果该文件中的cookie已经存在，则覆盖原文件写入</span></div></pre></td></tr></table></figure>
<p>3.从文件中获取Cookie 值并访问</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> cookielib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line"><span class="comment">#创造一个MozillaCookieJar实例对象</span></div><div class="line">cookie = cookielib.MozillaCookieJar()</div><div class="line"><span class="comment">#从文件中读入值到实例对象</span></div><div class="line">cookie.load(<span class="string">'cookie.txt'</span>, ignore_disgard = <span class="keyword">True</span>, ignore_expires = <span class="keyword">True</span>)</div><div class="line"><span class="comment">#创造请求的request</span></div><div class="line">request = urllib2.Request(<span class="string">"http://www.baidu.com"</span>)</div><div class="line"><span class="comment">#创建一个opener</span></div><div class="line">opener = urllib2.bulid_opener(urllib2.HTTPCookieProcessor(cookie))</div><div class="line">reponse = opener.open(request)</div><div class="line"><span class="keyword">print</span> reponse.read()</div></pre></td></tr></table></figure>
<p>4.利用cookie模拟网站的登录</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#示例。。登录校园网</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> http.cookiejar</div><div class="line"></div><div class="line">filename = <span class="string">'cookie.txt'</span></div><div class="line"></div><div class="line">cookie = http.cookiejar.MozillaCookieJar(filename)</div><div class="line"></div><div class="line">opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie))</div><div class="line"></div><div class="line">postdata = urllib.parse.urlencode(&#123;</div><div class="line">        <span class="string">'text'</span> : <span class="string">'2016xxxxxxxx'</span>,</div><div class="line">        <span class="string">'password'</span>   : <span class="string">'xxxxxxxxxxx'</span></div><div class="line">&#125;)</div><div class="line"></div><div class="line">loginurl = <span class="string">'http://ids.scuec.edu.cn/amserver/UI/Login?goto=http://eol.scuec.edu.cn/meol/homepage/common/sso_login.jsp'</span></div><div class="line"></div><div class="line">result = opener.open(loginurl, postdata.encode(<span class="string">'utf-8'</span>))</div><div class="line"></div><div class="line">cookie.save(ignore_discard=<span class="keyword">True</span>,ignore_expires=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">gradeurl = <span class="string">'http://eol.scuec.edu.cn/meol/jpk/course/layout/newpage/index.jsp?courseId=16574'</span></div><div class="line"></div><div class="line">result = opener.open(gradeurl)</div><div class="line"></div><div class="line"><span class="keyword">print</span> ((result.read()).decode(<span class="string">'gbk'</span>))</div></pre></td></tr></table></figure>
<h2 id="16-利用正则表达式"><a href="#16-利用正则表达式" class="headerlink" title="16.利用正则表达式"></a>16.利用正则表达式</h2><h4 id="1-定义：正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。"><a href="#1-定义：正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。" class="headerlink" title="1.定义：正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。"></a>1.定义：正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。</h4><p><img src="http://omg5mjb8v.bkt.clouddn.com/20130515113723855-e1424095177180.png" alt="正则表达式的语法规则"></p>
<h4 id="2-正则表达式的相关注解："><a href="#2-正则表达式的相关注解：" class="headerlink" title="2.正则表达式的相关注解："></a>2.正则表达式的相关注解：</h4><p>（1）数量词的贪婪模式与非贪婪模式</p>
<p>正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab<em>”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab</em>?”，将找到”a”。</p>
<p>注：我们一般使用非贪婪模式来提取。</p>
<h3 id="（2）反斜杠问题"><a href="#（2）反斜杠问题" class="headerlink" title="（2）反斜杠问题"></a>（2）反斜杠问题</h3><p>与大多数编程语言相同，正则表达式里使用”\”作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\”：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。</p>
<p>Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\”表示。同样，匹配一个数字的”\d”可以写成r”\d”。有了原生字符串，妈妈也不用担心是不是漏写了反斜杠，写出来的表达式也更直观了。</p>
<h2 id="17-两种表达方式"><a href="#17-两种表达方式" class="headerlink" title="17.两种表达方式"></a>17.两种表达方式</h2><p>XPath:/html/body/div[2]/ul/li[1]/img</p>
<p>CSS Selector:body &gt; div.main-content &gt; li:nth-child(1) &gt; img</p>
<h2 id="18-同步和异步加载"><a href="#18-同步和异步加载" class="headerlink" title="18.同步和异步加载"></a>18.同步和异步加载</h2><p>它允许无阻塞资源加载，并且使 onload 启动更快，允许页面内容加载，而不需要刷新页面，也可以根据页面内容延迟加载依赖。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//异步加载</span></div><div class="line">&lt;strong&gt;(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;  </div><div class="line">     <span class="keyword">var</span> s = <span class="built_in">document</span>.createElement(<span class="string">'script'</span>);  </div><div class="line">     s.type = <span class="string">'text/javascript'</span>;  </div><div class="line">     s.async = <span class="literal">true</span>;  </div><div class="line">     s.src = <span class="string">'http://yourdomain.com/script.js'</span>;  </div><div class="line">     <span class="keyword">var</span> x = <span class="built_in">document</span>.getElementsByTagName(<span class="string">'script'</span>)[<span class="number">0</span>];  </div><div class="line">     x.parentNode.insertBefore(s, x);  </div><div class="line"> &#125;)();<span class="xml"><span class="tag">&lt;/<span class="name">strong</span>&gt;</span></span></div></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//同步加载</span></div><div class="line">&lt;script src=<span class="string">"http://XXX.com/script.js"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></div></pre></td></tr></table></figure>
<p>同步模式，又称阻塞模式，会阻止浏览器的后续处理，停止了后续的解析，因此停止了后续的文件加载（如图像）、渲染、代码执行。一般的script标签（不带async等属性）加载时会阻塞浏览器，也就是说，浏览器在下载或执行该js代码块时，后面的标签不会被解析，例如在head中添加一个script，但这个script下载时网络不稳定，很长时间没有下载完成对应的js文件，那么浏览器此时一直等待这个js文件下载，此时页面不会被渲染，用户看到的就是白屏。以前的一般建议是把<script>放在页面末尾</body>之前，这样尽可能减少这种阻塞行为，而先让页面展示出来。</p>
<h2 id="19-抓取异步加载的数据"><a href="#19-抓取异步加载的数据" class="headerlink" title="19.抓取异步加载的数据"></a>19.抓取异步加载的数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_more_data</span><span class="params">(start, end)</span>:</span></div><div class="line">    <span class="keyword">for</span> one <span class="keyword">in</span> range(start, end):</div><div class="line">        get_data(url+str(one))</div><div class="line">        tome.sleep(<span class="number">1</span>)</div></pre></td></tr></table></figure>
<h2 id="20-使用MongoDB进行排版和插入"><a href="#20-使用MongoDB进行排版和插入" class="headerlink" title="20.使用MongoDB进行排版和插入"></a>20.使用MongoDB进行排版和插入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#使用mongodb进行简单的读取和插入</span></div><div class="line"><span class="keyword">import</span> pymongo</div><div class="line"></div><div class="line">client = pymongo.MongoClient(<span class="string">'localhost'</span>, <span class="number">27017</span>)</div><div class="line"></div><div class="line">DB = client[<span class="string">'DB'</span>]</div><div class="line"></div><div class="line">sheet_line = DB[<span class="string">'sheet_line'</span>]</div><div class="line"></div><div class="line">path = <span class="string">'/Users/mac/Desktop/1.md'</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> open(path, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">    lines = f.readlines()</div><div class="line">    <span class="keyword">for</span> index,line <span class="keyword">in</span> enumerate(lines):</div><div class="line">        data=&#123;</div><div class="line">                <span class="string">'line'</span>  : line,</div><div class="line">                <span class="string">'index'</span> : index,</div><div class="line">                <span class="string">'words'</span> : len(line.split())</div><div class="line">             &#125;</div><div class="line">        print(data)</div><div class="line">        sheet_line.insert_one(data)</div></pre></td></tr></table></figure>
<p>几种表达式：</p>
<blockquote>
<p>$lt:less than</p>
<p>$gt:greater than</p>
<p>$lte:less than equal</p>
<p>$gte:greater than equal</p>
<p>$ne:not equal</p>
</blockquote>
<p>e.g-&gt;sheet.find{word:{‘$lt’:5}},表示找到sheet中所有字数比五小的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#找出字数小于等于三的行数并输出其内容</span></div><div class="line"><span class="keyword">for</span> item <span class="keyword">in</span> sheet_line.find&#123;word:&#123;<span class="string">'$lte'</span>:<span class="number">3</span>&#125;&#125;:</div><div class="line">    print(item[<span class="string">'line'</span>])</div></pre></td></tr></table></figure>
<h2 id="21-爬取大规模数据的工作流分析"><a href="#21-爬取大规模数据的工作流分析" class="headerlink" title="21.爬取大规模数据的工作流分析"></a>21.爬取大规模数据的工作流分析</h2><p><img src="http://omg5mjb8v.bkt.clouddn.com/7B2E42E6-4839-4CCB-81FB-9D4785BDDA12.png" alt=""></p>
<p>在爬取大规模数据的时候，要分模块的去爬取</p>
<p>1.构造一个爬取所有网页的爬虫，将爬取到的网页存储到数据库中</p>
<p>2.再构造一个爬虫从数据中提取网址，爬取单个页面的信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#可以通过find方法来对不同的网页来进行适配,e.g:</span></div><div class="line"><span class="keyword">if</span> soup.find(<span class="string">'td'</span>,<span class="string">'t'</span>):</div><div class="line">	<span class="comment">#进行相关的爬取操作</span></div><div class="line"><span class="keyword">else</span>:</div><div class="line">    <span class="keyword">pass</span></div><div class="line"><span class="comment">#在对数据库进行插入操作的时候，也可以通过键值对的模式</span></div><div class="line"> sheet_line.insert_one(&#123;<span class="string">'url'</span> : <span class="string">'http://www.xxx.com'</span>&#125;)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#将爬取的单个页面信息插入到数据库中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_item_info</span><span class="params">(url)</span>:</span></div><div class="line">    web_data = requests.get(url)</div><div class="line">    soup = BeautifulSoup(web_data.text, <span class="string">'lxml'</span>)</div><div class="line">    title = soup.title.text</div><div class="line">    price = soup.select(<span class="string">'span.price.c_f50'</span>)[<span class="number">0</span>].text</div><div class="line">    date = soup.select(<span class="string">'.time'</span>)[<span class="number">0</span>].text</div><div class="line">    <span class="comment">#进一步容错的设置</span></div><div class="line">    area = list(soup.select(<span class="string">'.c_25d a'</span>)[<span class="number">0</span>].stripped_strings) <span class="keyword">if</span> soup.find_all(<span class="string">'span'</span>,<span class="string">'c_25d'</span>) <span class="keyword">else</span> <span class="keyword">None</span></div><div class="line">    item_info.insert_one(&#123;<span class="string">'title'</span>:title, <span class="string">'date'</span>:date, <span class="string">'area'</span>:area&#125;)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#对于404页面的判断，e.g:</span></div><div class="line"><span class="comment">#404页面示例</span></div><div class="line">&lt;script src=<span class="string">"http://www.douyu.com/js/404/jQuery-1.3.2.js"</span> type= <span class="string">"text/javascript"</span>&gt;</div><div class="line">no_longer_exist = <span class="string">'404'</span> <span class="keyword">in</span> soup.find(<span class="string">'script'</span>, type = <span class="string">"text/javascript"</span>).get(<span class="string">'src'</span>).split(<span class="string">'/'</span>)</div><div class="line"><span class="comment">#返回一个布尔型来判断，加上一个判断语句加入爬取页面信息的函数即可判断404</span></div></pre></td></tr></table></figure>
<h2 id="22-进程和线程"><a href="#22-进程和线程" class="headerlink" title="22.进程和线程"></a>22.进程和线程</h2><h3 id="形象的理解方式："><a href="#形象的理解方式：" class="headerlink" title="形象的理解方式："></a>形象的理解方式：</h3><blockquote>
<p>单进程单线程：一个餐馆里一张桌子一个人吃饭</p>
<p>单进程多线程：一个餐馆里一张桌子多个人吃饭</p>
<p>多进程单线程：一个餐馆里多张桌子，每张桌子一个人吃饭</p>
<p>多进程多线程：一个餐馆里多张桌子，每个桌子多个人吃法</p>
</blockquote>
<h2 id="23-多进程爬虫数据抓取"><a href="#23-多进程爬虫数据抓取" class="headerlink" title="23.多进程爬虫数据抓取"></a>23.多进程爬虫数据抓取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#需要用到的库</span></div><div class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</div><div class="line"><span class="keyword">from</span> channel_extract <span class="keyword">import</span> channel_list</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_links_from</span><span class="params">(channel)</span>:</span></div><div class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">101</span>):</div><div class="line">        get_link_from(channel,num)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    pool = Pool()</div><div class="line">    pool.map(get_all_links_from,channel_list.split())</div></pre></td></tr></table></figure>
<h3 id="map函数"><a href="#map函数" class="headerlink" title="map函数"></a>map函数</h3><p>map(function,interable,…):对于可迭代函数’iterable’中的每一个元素应用’function’方法，将结果作为list返回</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">e.g1-&gt;def add100(x):</div><div class="line">    	return x + 100</div><div class="line">    hh = [11,22,33]</div><div class="line">    hhh = map(add100,hh)</div><div class="line">#此时hhh的值为[111,122,133]</div><div class="line">#如果给出了额外的可迭代参数，则对每个可迭代参数中的元素‘并行’的应用‘function’。</div><div class="line">e.g2-&gt;def abc(a,b,c)</div><div class="line">	  	return a*10000 + b*100 + c</div><div class="line">	  list1 = [11,22,33]</div><div class="line">      list2 = [44,55,66]</div><div class="line">      list3 = [77,88,99]</div><div class="line">      hh = map(abc,list1,list2,list3)</div><div class="line">#此时hh的值为[114477,225588,336699],在每个list中，取出了下标相同的元素，执行了abc()。</div><div class="line">#如果'function'给出的是‘None’，自动假定一个‘identity’函数</div><div class="line">&gt;&gt;&gt; list1 = [11,22,33]</div><div class="line">&gt;&gt;&gt; map(None,list1)</div><div class="line">[11, 22, 33]</div><div class="line">&gt;&gt;&gt; list1 = [11,22,33]</div><div class="line">&gt;&gt;&gt; list2 = [44,55,66]</div><div class="line">&gt;&gt;&gt; list3 = [77,88,99]</div><div class="line">&gt;&gt;&gt; map(None,list1,list2,list3)</div><div class="line">[(11, 44, 77), (22, 55, 88), (33, 66, 99)]</div></pre></td></tr></table></figure>
<h2 id="24-爬取大规模数据实例代码"><a href="#24-爬取大规模数据实例代码" class="headerlink" title="24.爬取大规模数据实例代码"></a>24.爬取大规模数据实例代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#page_parsing.py</span></div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> pymongo</div><div class="line"></div><div class="line">client = pymongo.MongoClient(<span class="string">'localhost'</span>, <span class="number">27017</span>)</div><div class="line"></div><div class="line">ganji = client[<span class="string">'ganji'</span>]</div><div class="line"></div><div class="line">url_list = ganji[<span class="string">'url_list'</span>]</div><div class="line"></div><div class="line">item_info = ganji[<span class="string">'item_info'</span>]</div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'User-Agent'</span> : <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'</span>,</div><div class="line">    <span class="string">'Connection'</span> : <span class="string">'keep-alive'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">proxy_list = [</div><div class="line">    <span class="string">'http://121.232.147.178:9000'</span>,</div><div class="line">    <span class="string">'http://122.243.11.57:9000'</span>,</div><div class="line">    <span class="string">'http://121.232.145.163:9000'</span></div><div class="line">]</div><div class="line">proxy_ip = random.choice(proxy_list)</div><div class="line">proxies = &#123;<span class="string">'http'</span> : proxy_ip&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_links_from</span><span class="params">(channel,pages,who_sells=<span class="string">'o'</span>)</span>:</span></div><div class="line">    list_view = <span class="string">'&#123;&#125;/&#123;&#125;&#123;&#125;/'</span>.format(channel, str(who_sells), str(pages))</div><div class="line">    wb_data = requests.get(channel, headers=headers)</div><div class="line">    soup = BeautifulSoup(wb_data.text, <span class="string">'lxml'</span>)</div><div class="line">    <span class="keyword">if</span> soup.find(<span class="string">'ul'</span>, <span class="string">'pageLink'</span>):</div><div class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> soup.select(<span class="string">'td.t &gt; a.t'</span>):</div><div class="line">            item_link = link.get(<span class="string">'href'</span>).split(<span class="string">'?'</span>)[<span class="number">0</span>]</div><div class="line">            <span class="comment">#url_list.insert_one(&#123;'url':item_link&#125;)</span></div><div class="line">            <span class="comment">#print(item_link)</span></div><div class="line">            get_item_info_from(item_link)</div><div class="line">            print(<span class="string">'\n'</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment">#已经到达最后一页</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_item_info_from</span><span class="params">(url, data=None)</span>:</span></div><div class="line">    wb_data = requests.get(url, headers=headers)</div><div class="line">    <span class="keyword">if</span> wb_data.status_code == <span class="number">404</span>:</div><div class="line">        <span class="keyword">pass</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            soup = BeautifulSoup(wb_data.text, <span class="string">'lxml'</span>)</div><div class="line">            data = &#123;</div><div class="line">                <span class="string">'title'</span>:soup.title.text.strip(),</div><div class="line">                <span class="string">'price'</span>:soup.select(<span class="string">'.f22.fc-orange.f-type'</span>)[<span class="number">0</span>].text.strip(),</div><div class="line">                <span class="string">'pub_data'</span>:soup.select(<span class="string">'.pr-5'</span>)[<span class="number">0</span>].text.strip().split()[<span class="number">0</span>],</div><div class="line">                <span class="string">'area'</span>:list(map(<span class="keyword">lambda</span> x:x.text, soup.select(<span class="string">'ul.det-infor &gt; li &gt; a'</span>))),</div><div class="line">                <span class="string">'phoneNumber'</span>:soup.select(<span class="string">'span.phoneNum-style'</span>)[<span class="number">0</span>].text.strip(),</div><div class="line">                <span class="string">'url'</span>:url</div><div class="line">            &#125;</div><div class="line">            print(data)</div><div class="line">        <span class="comment">#except IndexError:</span></div><div class="line">            <span class="keyword">pass</span></div><div class="line">        <span class="keyword">except</span> AttributeError:</div><div class="line">            <span class="keyword">pass</span></div><div class="line"></div><div class="line"><span class="comment">#get_item_info_from('http://bj.ganji.com/shouji/29096013665341x.htm')</span></div><div class="line"><span class="comment">#get_links_from('http://bj.ganji.com/shouji',2)</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#channel_extracing.py</span></div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span>  BeautifulSoup</div><div class="line"></div><div class="line">start_url = <span class="string">'http://bj.ganji.com/wu'</span></div><div class="line">url_host = <span class="string">'http://bj.ganji.com'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_index_url</span><span class="params">(url)</span>:</span></div><div class="line">    wb_data = requests.get(url)</div><div class="line">    soup = BeautifulSoup(wb_data.text, <span class="string">'lxml'</span>)</div><div class="line">    links = soup.select(<span class="string">'.fenlei &gt; dt &gt; a'</span>)</div><div class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links:</div><div class="line">        page_url = url_host + link.get(<span class="string">'href'</span>)</div><div class="line">        print(page_url)</div><div class="line"></div><div class="line"><span class="comment">#get_index_url(start_url)</span></div><div class="line"></div><div class="line">channel_list = <span class="string">'''</div><div class="line">http://bj.ganji.com/jiaju/</div><div class="line">http://bj.ganji.com/rirongbaihuo/</div><div class="line">http://bj.ganji.com/shouji/</div><div class="line">http://bj.ganji.com/shoujihaoma/</div><div class="line">http://bj.ganji.com/bangong/</div><div class="line">http://bj.ganji.com/nongyongpin/</div><div class="line">http://bj.ganji.com/jiadian/</div><div class="line">http://bj.ganji.com/ershoubijibendiannao/</div><div class="line">http://bj.ganji.com/ruanjiantushu/</div><div class="line">http://bj.ganji.com/yingyouyunfu/</div><div class="line">http://bj.ganji.com/diannao/</div><div class="line">http://bj.ganji.com/xianzhilipin/</div><div class="line">http://bj.ganji.com/fushixiaobaxuemao/</div><div class="line">http://bj.ganji.com/meironghuazhuang/</div><div class="line">http://bj.ganji.com/shuma/</div><div class="line">http://bj.ganji.com/laonianyongpin/</div><div class="line">http://bj.ganji.com/xuniwupin/</div><div class="line">http://bj.ganji.com/qitawupin/</div><div class="line">http://bj.ganji.com/ershoufree/</div><div class="line">http://bj.ganji.com/wupinjiaohuan/</div><div class="line">'''</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#main.py</span></div><div class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</div><div class="line"><span class="keyword">from</span> channel_extracing <span class="keyword">import</span> channel_list</div><div class="line"><span class="keyword">from</span> page_parsing <span class="keyword">import</span> get_item_info_from,get_links_from,url_list,item_info</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_links</span><span class="params">(channel)</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">100</span>):</div><div class="line">        get_links_from(channel, i)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    pool = Pool()</div><div class="line">    pool.map(get_all_links, channel_list.split())</div><div class="line">    pool.close()</div><div class="line">    pool.join()</div></pre></td></tr></table></figure>
<h2 id="25-更新数据库"><a href="#25-更新数据库" class="headerlink" title="25.更新数据库"></a>25.更新数据库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">db.collection.update()</div><div class="line"><span class="comment">#update函数的用法,一般传入两个参数</span></div><div class="line">update(&#123;id:<span class="number">1</span>&#125;,&#123;$set:&#123;name:<span class="number">2</span>&#125;&#125;)</div></pre></td></tr></table></figure>
<h2 id="26-突破爬虫封禁的几种方法参考"><a href="#26-突破爬虫封禁的几种方法参考" class="headerlink" title="26.突破爬虫封禁的几种方法参考"></a>26.突破爬虫封禁的几种方法<a href="http://bigsec.com/bigsec-news/wechat-2016-web-crawler?ref=bigsec-news1">参考</a></h2><p>1.构造合理的HTTP头部请求</p>
<p>2.学会正确的设置cookie</p>
<p>3.正确的时间访问路径（不能访问过快）</p>
<p>4.隐含输入字段值（honey pot）</p>
<p>5.使用可变的远程ip（Tor代理服务器，防止ip被ban）</p>
<p>6.动态页面模拟人为操作（selenium+phantomJS框架）</p>
</script></p>
      
      
        <div class="page-reward">
          <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang" title="打赏，支持一下">赏</a></p>
          <div class="hide_box"></div>
          <div class="shang_box">
            <a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()" title="关闭">×</a>
            <div class="shang_tit">
              <p>纯属好玩</p>
            </div>
            <div class="shang_payimg">
              <img src="/img/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
            </div>
              <div class="pay_explain">点击下方的图片，扫码打赏，你说多少就多少</div>
            <div class="shang_payselect">
              
                <div class="pay_item checked" data-id="alipay">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/123.png" alt="支付宝" /></span>
                </div>
              
              
                <div class="pay_item" data-id="wechat">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/wc.png" alt="微信" /></span>
                </div>
              
            </div>
            <div class="shang_info">
              <p>打开<span id="shang_pay_txt">支付宝</span>扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
        </div>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js"></script>
        <script type="text/javascript">
          $(".pay_item").click(function(){
            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');
            var dataid=$(this).attr('data-id');
            $(".shang_payimg img").attr("src","/img/"+dataid+"img.jpg");
            $("#shang_pay_txt").text(dataid=="alipay"?"支付宝":"微信");
          });
          function dashangToggle(){
            $(".hide_box").fadeToggle();
            $(".shang_box").fadeToggle();
          }
        </script>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2017/05/12/网络爬虫/">网络爬虫</a></p>
        <p><span>文章作者:</span><a href="/" title="访问 Peter pan 的个人博客">Peter pan</a></p>
        <p><span>发布时间:</span>2017年05月12日 - 19时48分</p>
        <p><span>最后更新:</span>2017年05月12日 - 20时03分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2017/05/12/网络爬虫/" title="网络爬虫">http://yoursite.com/2017/05/12/网络爬虫/</a>
            <span class="copy-path" data-clipboard-text="原文: http://yoursite.com/2017/05/12/网络爬虫/　　作者: Peter pan" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script src="/js/clipboard.min.js"></script>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



<nav id="article-nav">
  
    <a href="/2017/05/12/网络爬虫-二/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          网络爬虫(二)
        
      </div>
    </a>
  
  
    <a href="/2017/05/12/RSA密钥生成的过程-数学证明/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">RSA密钥生成的过程(数学证明)</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#网络爬虫"><span class="toc-number">1.</span> <span class="toc-text">网络爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-urlopen"><span class="toc-number">1.1.</span> <span class="toc-text">1.urlopen:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-urlretrieve"><span class="toc-number">1.2.</span> <span class="toc-text">2.urlretrieve():</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-使用正则获取图片并保存在本地"><span class="toc-number">1.3.</span> <span class="toc-text">3.使用正则获取图片并保存在本地</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-urlencode-GET和POST方法"><span class="toc-number">1.4.</span> <span class="toc-text">4.urlencode,GET和POST方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-urllib2和伪造请求头部"><span class="toc-number">1.5.</span> <span class="toc-text">5.urllib2和伪造请求头部</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-BeautifulSoup参考文章"><span class="toc-number">1.6.</span> <span class="toc-text">6.BeautifulSoup参考文章</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-使用select不断筛选-取得属性"><span class="toc-number">1.7.</span> <span class="toc-text">7.使用select不断筛选,取得属性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-urlopen的分析"><span class="toc-number">1.8.</span> <span class="toc-text">8.urlopen的分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-构造Request"><span class="toc-number">1.9.</span> <span class="toc-text">9.构造Request</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-Proxy（代理）的设置"><span class="toc-number">1.10.</span> <span class="toc-text">10.Proxy（代理）的设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-Timeout设置"><span class="toc-number">1.11.</span> <span class="toc-text">11.Timeout设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-PUT和DELETE方法"><span class="toc-number">1.12.</span> <span class="toc-text">12.PUT和DELETE方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-URLError"><span class="toc-number">1.13.</span> <span class="toc-text">13.URLError</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-Opener概念"><span class="toc-number">1.14.</span> <span class="toc-text">14.Opener概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-Cookielib"><span class="toc-number">1.15.</span> <span class="toc-text">15.Cookielib</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-利用正则表达式"><span class="toc-number">1.16.</span> <span class="toc-text">16.利用正则表达式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-定义：正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。"><span class="toc-number">1.16.0.1.</span> <span class="toc-text">1.定义：正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-正则表达式的相关注解："><span class="toc-number">1.16.0.2.</span> <span class="toc-text">2.正则表达式的相关注解：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（2）反斜杠问题"><span class="toc-number">1.16.1.</span> <span class="toc-text">（2）反斜杠问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-两种表达方式"><span class="toc-number">1.17.</span> <span class="toc-text">17.两种表达方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#18-同步和异步加载"><span class="toc-number">1.18.</span> <span class="toc-text">18.同步和异步加载</span></a></li></ol></li></ol>
</div>
<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";

    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }
    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
        }
    })
    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
    }
</script>





<div class="bdsharebuttonbox">
	<a href="#" class="fx fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="fx fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="fx fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="fx fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="fx fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="fx fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
	<a href="#" class="fx fa-files-o bds_copy" data-cmd="copy" title="分享到复制网址"></a>
</div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>




    
      <div class="duoshuo" id="comments">
    <!-- 多说评论框 start -->
    <div class="ds-thread" data-thread-key="2017/05/12/网络爬虫/" data-title="网络爬虫" data-url="http://yoursite.com/2017/05/12/网络爬虫/"></div>
    <!-- 多说评论框 end -->
    <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
    <script type="text/javascript">
    var duoshuoQuery = {short_name:"null"};
    (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = '/js/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] 
         || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
    </script>
    <!-- 多说公共JS代码 end -->
</div>

    



    <div class="scroll" id="post-nav-button">
        
            <a href="/2017/05/12/网络爬虫-二/" title="上一篇: 网络爬虫(二)">
                <i class="fa fa-angle-left"></i>
            </a>
        
        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>
        
            <a href="/2017/05/12/RSA密钥生成的过程-数学证明/" title="下一篇: RSA密钥生成的过程(数学证明)">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>
    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/06/26/iOS成员变量和属性的关系/">iOS成员变量和属性的关系</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/26/ARC与分类/">ARC与分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/24/内存管理/">内存管理</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/21/OC特有语法/">OC特有语法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/20/Xcode基本调试/">Xcode基本调试</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/15/iOS-UI基础-七/">iOS-UI基础(七)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/15/七牛图片自动上传/">七牛图片自动上传</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/14/CPU对于内存的读写/">CPU对于内存的读写</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/11/iOS-UI学习-六/">iOS-UI学习(六)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/03/iOS-UI学习-五/">iOS-UI学习(五)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/26/Web基础/">Web基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/23/iOS-UI学习-四/">iOS-UI学习(四)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/22/Linux进程/">Linux进程</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/18/jupyter笔记本基本使用/">jupyter笔记本基本使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/18/iOS-UI学习-三/">iOS-UI学习(三)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/12/iOS-UI学习-二/">iOS-UI学习(二)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/12/iOS-UI学习/">iOS-UI学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/12/网络爬虫-二/">网络爬虫(二)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/12/网络爬虫/">网络爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/12/RSA密钥生成的过程-数学证明/">RSA密钥生成的过程(数学证明)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/12/土家购农村电商爬虫代码示例/">土家购农村电商爬虫代码示例</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/21/多终端同步hexo博客/">多终端同步hexo博客</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/20/hello-world/">页面教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/20/秒速五厘米/">秒速五厘米</a></li></ul>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
    <script>
        $(".post-list").addClass("toc-article");
        $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
            }
        })
    </script>



    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2017 Peter pan
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/luuman/hexo-theme-spfk" target="_blank">spfk</a> by luuman
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >海贼到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


  </div>
</body>
</html>